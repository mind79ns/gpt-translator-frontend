// translate.js (Netlify function) - AI ë¬¸ë§¥ ë²ˆì—­ ê³ ë„í™” ì§€ì› v6.0
// ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
// 1. AI ë¬¸ë§¥ ë²ˆì—­ ê¸°ëŠ¥ ì¶”ê°€ (useAIContext, contextualPrompt, qualityLevel)
// 2. ì „ë¬¸ìš©ì–´ ì‚¬ì „ ë° ë²ˆì—­ ìŠ¤íƒ€ì¼ ì§€ì›
// 3. í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ ë° ì„¤ì • ì¡°ì •
// 4. ê¸°ì¡´ ê¸°ëŠ¥ ì™„ì „ í˜¸í™˜ì„± ìœ ì§€

let fetchFn = globalThis.fetch;
try {
  if (!fetchFn) fetchFn = require('node-fetch');
} catch (e) {
  fetchFn = globalThis.fetch || null;
}

// ğŸ”§ ì¶”ê°€: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
const { 
  verifyToken, 
  getUserApiKey, 
  trackUsage, 
  getPublicCache, 
  setPublicCache 
} = require('./database');

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';
const GOOGLE_TTS_API_KEY = process.env.GOOGLE_TTS_API_KEY || '';
const MAX_INPUT_CHARS = 6000;
const TRANSLATION_CACHE_TTL_MS = 1000 * 60 * 60;

const translationCache = new Map();

function setCache(key, value) {
  translationCache.set(key, { ts: Date.now(), value });
}

function getCache(key) {
  const entry = translationCache.get(key);
  if (!entry) return null;
  if (Date.now() - entry.ts > TRANSLATION_CACHE_TTL_MS) {
    translationCache.delete(key);
    return null;
  }
  return entry.value;
}

function detectSourceLanguage(text) {
  const koreanRegex = /[ê°€-í£]/;
  const vietnameseRegex = /[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘Ä]/i;
  if (koreanRegex.test(text)) return "Korean";
  if (vietnameseRegex.test(text)) return "Vietnamese";
  return "English";
}

async function retryWithBackoff(fn, attempts = 3, baseDelay = 300) {
  let lastErr;
  for (let i = 0; i < attempts; i++) {
    try {
      return await fn();
    } catch (err) {
      lastErr = err;
      const jitter = Math.random() * 200;
      const delay = baseDelay * Math.pow(2, i) + jitter;
      await new Promise(res => setTimeout(res, delay));
    }
  }
  throw lastErr;
}

// ğŸ§  ìƒˆë¡œìš´ AI ë¬¸ë§¥ ë²ˆì—­ í•¨ìˆ˜
async function translateWithAIContext(inputText, targetLang, contextualPrompt, qualityLevel = 3, getPronunciation = true, userApiKey = null) {
  const apiKey = userApiKey || OPENAI_API_KEY;
  if (!apiKey) throw new Error("ì„œë²„ ì˜¤ë¥˜: API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.");
  if (!inputText || inputText.trim().length === 0) throw new Error("ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
  if (inputText.length > MAX_INPUT_CHARS) throw new Error(`ì…ë ¥ ê¸¸ì´ ì´ˆê³¼ (ìµœëŒ€ ${MAX_INPUT_CHARS}ì)`);

  // ğŸ”§ ê³µìš© ìºì‹œ í™•ì¸ (AI ëª¨ë“œê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
  if (!contextualPrompt || contextualPrompt.trim() === '') {
    const publicCache = await getPublicCache(inputText, targetLang);
    if (publicCache.success) {
      return {
        translation: publicCache.data.translation,
        pronunciation_hangul: publicCache.data.pronunciation || ''
      };
    }
  }

  const cacheKey = `ai_tr:${targetLang}:${inputText}:${qualityLevel}:${getPronunciation}:${contextualPrompt.substring(0, 100)}`;
  const cached = getCache(cacheKey);
  if (cached) return cached;

  const sourceLanguage = detectSourceLanguage(inputText);

  // í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ëª¨ë¸ ë° ì„¤ì • ì„ íƒ
  const qualityConfig = {
    1: { model: "gpt-4o-mini", temperature: 0.3, maxTokens: 1000 },
    2: { model: "gpt-4o-mini", temperature: 0.1, maxTokens: 1200 },
    3: { model: "gpt-4o", temperature: 0.0, maxTokens: 1500 },
    4: { model: "gpt-4o", temperature: 0.0, maxTokens: 2000 },
    5: { model: "gpt-4o", temperature: 0.0, maxTokens: 2500 }
  };

  const config = qualityConfig[qualityLevel] || qualityConfig[3];

  let systemMessage = `
You are an elite professional translator with deep cultural understanding and linguistic expertise.
ALWAYS return only valid JSON (no extra commentary, no markdown).
The JSON MUST contain exactly two keys: "translation" (string), "pronunciation_hangul" (string).

Core Translation Rules:
- Source language: ${sourceLanguage} â†’ Target language: ${targetLang}
- Preserve named entities, proper nouns, product codes, and URLs exactly as-is
- Maintain appropriate formality level based on context
- Ensure natural, fluent expression in target language`;

  // í’ˆì§ˆ ë ˆë²¨ì— ë”°ë¥¸ ì¶”ê°€ ì§€ì¹¨
  if (qualityLevel >= 4) {
    systemMessage += `
- PREMIUM QUALITY: Consider cultural nuances, idiomatic expressions, and regional variations
- Apply advanced linguistic analysis for context-appropriate translations
- Ensure perfect grammar and natural flow`;
  } else if (qualityLevel >= 3) {
    systemMessage += `
- HIGH QUALITY: Focus on accuracy and natural expression
- Consider context and maintain consistency`;
  }

  if (getPronunciation) {
    systemMessage += `
- Provide "pronunciation_hangul" as accurate Korean phonetic transcription of the translated ${targetLang} text
- For Vietnamese: use Korean characters to represent Vietnamese pronunciation (í•œê¸€ í‘œê¸°)
- For English: use Korean characters to represent English pronunciation`;
  } else {
    systemMessage += `
- Set "pronunciation_hangul" to an empty string`;
  }

  systemMessage += `
- Output format: Return ONLY valid JSON, no other text`;

  // contextualPromptë¥¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ í™œìš©
  const userPrompt = contextualPrompt || `Translate this ${sourceLanguage} text to ${targetLang}: """${inputText}"""`;

  const payload = {
    model: config.model,
    messages: [
      { role: "system", content: systemMessage },
      { role: "user", content: userPrompt }
    ],
    temperature: config.temperature,
    max_tokens: config.maxTokens
  };

  console.log('[AI Translation] ì‚¬ìš© ëª¨ë¸:', config.model, 'í’ˆì§ˆ ë ˆë²¨:', qualityLevel);

  const parsed = await retryWithBackoff(async () => {
   const resp = await fetchFn("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(payload)
    });

    if (!resp.ok) {
      const txt = await resp.text();
      throw new Error(`AI ë²ˆì—­ API ì˜¤ë¥˜ ${resp.status}: ${txt}`);
    }
    const data = await resp.json();
    const content = data?.choices?.[0]?.message?.content;
    if (!content) throw new Error("AI ë²ˆì—­ ì‘ë‹µ ì—†ìŒ");

    try {
      return JSON.parse(content);
    } catch (e) {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ë¦¬ ì‹œë„
      const s = content.indexOf('{'), eidx = content.lastIndexOf('}');
      if (s !== -1 && eidx !== -1) {
        const maybe = content.substring(s, eidx + 1);
        return JSON.parse(maybe);
      }
      throw new Error("AI ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    }
  }, 3, 300);

  const safe = {
    translation: (parsed.translation || parsed.translated_text || "").toString(),
    pronunciation_hangul: (parsed.pronunciation_hangul || parsed.pronunciation || parsed.pron || "").toString()
  };

  setCache(cacheKey, safe);
  
  // ğŸ”§ ê³µìš© ìºì‹œì—ë„ ì €ì¥ (ì¼ë°˜ ë²ˆì—­ì¸ ê²½ìš°ë§Œ)
  if (!contextualPrompt || contextualPrompt.trim() === '') {
    await setPublicCache(inputText, targetLang, safe.translation, safe.pronunciation_hangul);
  }
  
  return safe;
}

// ê¸°ì¡´ ì¼ë°˜ ë²ˆì—­ í•¨ìˆ˜ (í˜¸í™˜ì„± ìœ ì§€)
async function translateAndPronounceSingleCall(inputText, targetLang, getPronunciation = true, userApiKey = null) {
  const apiKey = userApiKey || OPENAI_API_KEY;
  if (!apiKey) throw new Error("ì„œë²„ ì˜¤ë¥˜: API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.");
  
  // ğŸ”§ ê³µìš© ìºì‹œ í™•ì¸
  const publicCache = await getPublicCache(inputText, targetLang);
  if (publicCache.success) {
    return {
      translation: publicCache.data.translation,
      pronunciation_hangul: publicCache.data.pronunciation || ''
    };
  }
  if (!inputText || inputText.trim().length === 0) throw new Error("ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
  if (inputText.length > MAX_INPUT_CHARS) throw new Error(`ì…ë ¥ ê¸¸ì´ ì´ˆê³¼ (ìµœëŒ€ ${MAX_INPUT_CHARS}ì)`);

  const cacheKey = `tr:${targetLang}:${inputText}:${getPronunciation}`;
  const cached = getCache(cacheKey);
  if (cached) return cached;

  const sourceLanguage = detectSourceLanguage(inputText);

  let systemMessage = `
You are a professional, consistent translator. ALWAYS return only valid JSON (no extra commentary).
The JSON MUST contain two keys: "translation" (string), "pronunciation_hangul" (string).
Rules:
- Translate the given ${sourceLanguage} text to ${targetLang}.
- Preserve named entities, product codes, and email/URLs as-is.
- Maintain formality: if the input is formal, use formal polite tone; otherwise neutral.
- Keep translation concise and natural.`;

  if (getPronunciation) {
    systemMessage += `
- Provide "pronunciation_hangul" as a Korean-readable transcription of the translated ${targetLang} text (for Vietnamese: í•œê¸€ í‘œê¸°).`;
  } else {
    systemMessage += `
- Set "pronunciation_hangul" to an empty string.`;
  }

  systemMessage += `
- Return only JSON (no markdown, no explanation).`;

  const userPrompt = `Text: """${inputText}"""`;

  const payload = {
    model: "gpt-4o",
    messages: [
      { role: "system", content: systemMessage },
      { role: "user", content: userPrompt }
    ],
    temperature: 0.0,
    max_tokens: 1500
  };

  const parsed = await retryWithBackoff(async () => {
    const resp = await fetchFn("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(payload)
    });

    if (!resp.ok) {
      const txt = await resp.text();
      throw new Error(`ë²ˆì—­ API ì˜¤ë¥˜ ${resp.status}: ${txt}`);
    }
    const data = await resp.json();
    const content = data?.choices?.[0]?.message?.content;
    if (!content) throw new Error("ë²ˆì—­ ì‘ë‹µ ì—†ìŒ");

    try {
      return JSON.parse(content);
    } catch (e) {
      const s = content.indexOf('{'), eidx = content.lastIndexOf('}');
      if (s !== -1 && eidx !== -1) {
        const maybe = content.substring(s, eidx + 1);
        return JSON.parse(maybe);
      }
      throw new Error("ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    }
  }, 3, 300);

  const safe = {
    translation: (parsed.translation || parsed.translated_text || "").toString(),
    pronunciation_hangul: (parsed.pronunciation_hangul || parsed.pronunciation || parsed.pron || "").toString()
  };

  setCache(cacheKey, safe);
  
  // ğŸ”§ ê³µìš© ìºì‹œì—ë„ ì €ì¥
  await setPublicCache(inputText, targetLang, safe.translation, safe.pronunciation_hangul);
  
  return safe;
}

// ë¬¸ì¥ ë¶„í•  í—¬í¼
function splitIntoSentences(text, maxLength = 200) {
  const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];
  const chunks = [];
  
  let currentChunk = '';
  for (const sentence of sentences) {
    if ((currentChunk + sentence).length <= maxLength) {
      currentChunk += sentence;
    } else {
      if (currentChunk) chunks.push(currentChunk.trim());
      currentChunk = sentence;
    }
  }
  if (currentChunk) chunks.push(currentChunk.trim());
  
  return chunks;
}

// Google Cloud TTS (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
async function getGoogleTTS(text, languageCode = 'vi-VN', voiceName = null, speakingRate = 1.0) {
  console.log('[Google TTS] ì‹œì‘:', { 
    text: text.substring(0, 50), 
    languageCode, 
    voiceName,
    speakingRate 
  });
  
  try {
    if (!process.env.GOOGLE_SERVICE_ACCOUNT_JSON) {
      console.error('GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ');
      return await getOpenAITTS(text, 'nova');
    }
    
    const { GoogleAuth } = require('google-auth-library');
    const serviceAccount = JSON.parse(process.env.GOOGLE_SERVICE_ACCOUNT_JSON);

    const auth = new GoogleAuth({
      credentials: serviceAccount,
      scopes: ['https://www.googleapis.com/auth/cloud-platform']
    });

    const client = await auth.getClient();
    const accessToken = await client.getAccessToken();
    
    if (!accessToken || !accessToken.token) {
      console.error('Google ì•¡ì„¸ìŠ¤ í† í° ì—†ìŒ');
      return await getOpenAITTS(text, 'nova');
    }

    let selectedVoice = voiceName;
    
    if (!selectedVoice) {
      if (languageCode.startsWith('vi')) {
        selectedVoice = 'vi-VN-Standard-A';
      } else if (languageCode.startsWith('ko')) {
        selectedVoice = 'ko-KR-Standard-A';
      } else {
        selectedVoice = 'en-US-Standard-C';
      }
    }
    
    const voiceLangCode = selectedVoice.substring(0, 5);
    const requestLangCode = languageCode.substring(0, 5);
    
    if (voiceLangCode !== requestLangCode) {
      console.log(`[Google TTS] ì–¸ì–´ ì½”ë“œ ë¶ˆì¼ì¹˜ ê°ì§€: voice=${voiceLangCode}, request=${requestLangCode}`);
      
      if (requestLangCode === 'vi-VN') {
        selectedVoice = voiceName?.includes('-B') || voiceName?.includes('-D') ? 'vi-VN-Standard-B' : 'vi-VN-Standard-A';
      } else if (requestLangCode === 'ko-KR') {
        selectedVoice = voiceName?.includes('-C') || voiceName?.includes('-D') ? 'ko-KR-Standard-C' : 'ko-KR-Standard-A';
      }
    }
    
    console.log('[Google TTS] ìµœì¢… ì„ íƒëœ ìŒì„±:', selectedVoice);
    
    const fetchFunction = fetchFn || require('node-fetch');
    
    const requestBody = {
      input: { text: text },
      voice: { 
        languageCode: languageCode, 
        name: selectedVoice
      },
      audioConfig: { 
        audioEncoding: 'MP3',
        speakingRate: speakingRate || 1.0,
        pitch: 0.0,
        volumeGainDb: 10.0
      }
    };
    
    const response = await fetchFunction(
      'https://texttospeech.googleapis.com/v1/text:synthesize',
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${accessToken.token}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      }
    );

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`Google TTS API ì˜¤ë¥˜ ${response.status}:`, errorText);
      return await getOpenAITTS(text, 'nova');
    }

    const data = await response.json();
    
    if (!data.audioContent) {
      console.error('audioContent ì—†ìŒ:', data);
      return await getOpenAITTS(text, 'nova');
    }
    
    const audioBuffer = Buffer.from(data.audioContent, 'base64');
    
    console.log('[Google TTS] ì„±ê³µ:', {
      voice: selectedVoice,
      audioSize: audioBuffer.length,
      isBuffer: Buffer.isBuffer(audioBuffer)
    });
    
    return audioBuffer;
    
  } catch (err) {
    console.error('[Google TTS] ì‹¤íŒ¨:', err.message);
    try {
      console.log('[Google TTS] OpenAIë¡œ í´ë°± ì‹œë„');
      return await getOpenAITTS(text, 'nova');
    } catch (fallbackErr) {
      console.error('[Google TTS] í´ë°±ë„ ì‹¤íŒ¨:', fallbackErr.message);
      throw fallbackErr;
    }
  }
}

// ğŸ”§ ê°œì„ : OpenAI TTS (API í‚¤ íŒŒë¼ë¯¸í„° ê°•í™”)
async function getOpenAITTS(text, voice = 'alloy', apiKey = null) {
  const ttsApiKey = apiKey || OPENAI_API_KEY;
  const isUserKey = !!apiKey;
  
  if (!ttsApiKey) {
    throw new Error("ì„œë²„ ì˜¤ë¥˜: API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.");
  }
  
  // í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (OpenAI TTS ìµœëŒ€ 4096ì)
  const trimmed = text.length > 4000 ? text.slice(0, 4000) : text;
  
  console.log(`[OpenAI TTS] ìš”ì²­: ${trimmed.length}ì, ìŒì„±: ${voice}, í‚¤íƒ€ì…: ${isUserKey ? 'ì‚¬ìš©ì' : 'ì‹œìŠ¤í…œ'}`);

  const body = {
    model: 'tts-1-hd',
    input: trimmed,
    voice: voice
  };

  const arrBuff = await retryWithBackoff(async () => {
    const resp = await fetchFn("https://api.openai.com/v1/audio/speech", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${ttsApiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(body)
    });
    
    if (!resp.ok) {
      const txt = await resp.text();
      console.error(`[OpenAI TTS] API ì˜¤ë¥˜ ${resp.status}:`, txt);
      
      // ì‚¬ìš©ì í‚¤ì¼ ë•Œ ë” êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€
      if (isUserKey && resp.status === 401) {
        throw new Error('ì‚¬ìš©ì API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
      } else if (resp.status === 429) {
        throw new Error('API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      } else {
        throw new Error(`TTS ì˜¤ë¥˜ ${resp.status}: ${txt}`);
      }
    }
    
    return await resp.arrayBuffer();
  }, 3, 400);
  
  const buffer = Buffer.from(arrBuff);
  console.log(`[OpenAI TTS] ì„±ê³µ: ${buffer.length}ë°”ì´íŠ¸ ìƒì„±`);
  
  return buffer;
}

// ğŸš€ ë©”ì¸ í•¸ë“¤ëŸ¬ - AI ë¬¸ë§¥ ë²ˆì—­ ê¸°ëŠ¥ í†µí•©
exports.handler = async function (event, context) {
  const commonHeaders = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    'Access-Control-Allow-Methods': 'POST, OPTIONS'
  };

  if (event.httpMethod === "OPTIONS") {
    return { statusCode: 200, headers: commonHeaders, body: '' };
  }
  if (event.httpMethod !== "POST") {
    return { statusCode: 405, headers: { ...commonHeaders, 'Content-Type': 'application/json' }, body: JSON.stringify({ error: "Method Not Allowed" }) };
  }

  try {
   // ğŸ”§ ê°œì„ : ì‚¬ìš©ì ì¸ì¦ ì²˜ë¦¬
const authHeader = event.headers.authorization || event.headers.Authorization;
let userId = null;
let userApiKeys = { openai: null, google: null };

if (authHeader && authHeader.startsWith('Bearer ')) {
  const token = authHeader.substring(7);
  const authResult = await verifyToken(token);
  
  if (authResult.success) {
    userId = authResult.userId;
    console.log(`[Auth] ì‚¬ìš©ì ì¸ì¦ ì„±ê³µ: ${userId}`);
    
    // ì‚¬ìš©ì API í‚¤ ë³‘ë ¬ ì¡°íšŒë¡œ ì„±ëŠ¥ ê°œì„ 
    const [openaiKeyResult, googleKeyResult] = await Promise.all([
      getUserApiKey(userId, 'openai'),
      getUserApiKey(userId, 'google')
    ]);
    
    userApiKeys = {
      openai: openaiKeyResult.success ? openaiKeyResult.apiKey : null,
      google: googleKeyResult.success ? googleKeyResult.apiKey : null
    };
    
    console.log(`[Auth] API í‚¤ ë¡œë“œ ì™„ë£Œ - OpenAI: ${!!userApiKeys.openai}, Google: ${!!userApiKeys.google}`);
  } else {
    console.log(`[Auth] í† í° ê²€ì¦ ì‹¤íŒ¨: ${authResult.error}`);
  }
} else {
  console.log('[Auth] ì¸ì¦ í—¤ë” ì—†ìŒ - ê²ŒìŠ¤íŠ¸ ëª¨ë“œ');
}
    
    const { 
      action, 
      inputText, 
      targetLang, 
      voice, 
      language, 
      chunkIndex, 
      useGoogleTTS, 
      voiceName,
      getPronunciation = true,
      // ğŸ§  ìƒˆë¡œìš´ AI ë¬¸ë§¥ ë²ˆì—­ íŒŒë¼ë¯¸í„°ë“¤
      useAIContext = false,
      contextualPrompt = null,
      qualityLevel = 3
    } = JSON.parse(event.body || '{}');

    if (!OPENAI_API_KEY) {
      throw new Error("ì„œë²„ ì„¤ì • ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.");
    }

    if (action === 'translate') {
  if (!inputText || !targetLang) {
    return { 
      statusCode: 400, 
      headers: { ...commonHeaders, 'Content-Type': 'application/json' }, 
      body: JSON.stringify({ error: "inputTextì™€ targetLangì´ í•„ìš”í•©ë‹ˆë‹¤." }) 
    };
  }
  
  // ğŸ”§ ê°œì„ : API í‚¤ ì„ íƒ ë¡œì§ ê°•í™”
  const apiKeyToUse = userApiKeys?.openai || OPENAI_API_KEY;
  const isUserKey = !!userApiKeys?.openai;
  
  if (!apiKeyToUse) {
    return {
      statusCode: 500,
      headers: { ...commonHeaders, 'Content-Type': 'application/json' },
      body: JSON.stringify({ error: "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." })
    };
  }
  
  console.log(`[Translation] ${isUserKey ? 'ì‚¬ìš©ì' : 'ì‹œìŠ¤í…œ'} API í‚¤ ì‚¬ìš©, ëª¨ë“œ: ${useAIContext ? 'AI' : 'ì¼ë°˜'}`);
  
  let result;
  
  try {
    // ğŸ§  AI ë¬¸ë§¥ ë²ˆì—­ vs ì¼ë°˜ ë²ˆì—­ ë¶„ê¸°
    if (useAIContext && contextualPrompt) {
      console.log('[Translation] AI ë¬¸ë§¥ ë²ˆì—­ ëª¨ë“œ, í’ˆì§ˆ ë ˆë²¨:', qualityLevel);
      result = await translateWithAIContext(
        inputText, 
        targetLang, 
        contextualPrompt, 
        qualityLevel, 
        getPronunciation,
        apiKeyToUse
      );
    } else {
      console.log('[Translation] ì¼ë°˜ ë²ˆì—­ ëª¨ë“œ');
      result = await translateAndPronounceSingleCall(inputText, targetLang, getPronunciation, apiKeyToUse);
    }
    
    // ğŸ”§ ê°œì„ : ì‚¬ìš©ëŸ‰ ì¶”ì  ê°•í™”
    if (userId) {
      const cost = inputText.length * 0.000015; // OpenAI ìš”ê¸ˆ ê³„ì‚°
      await trackUsage(userId, 'translation', inputText.length, cost, 'openai');
      console.log(`[Usage] ì‚¬ìš©ëŸ‰ ì¶”ì : ${inputText.length}ì, ë¹„ìš©: $${cost.toFixed(6)}`);
    }
    
    // ë¬¸ì¥ ë¶„í•  ì¶”ê°€
    const chunks = splitIntoSentences(result.translation);
    result.chunks = chunks;
    
    // AI ëª¨ë“œ í‘œì‹œë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
    if (useAIContext) {
      result.isAITranslation = true;
      result.qualityLevel = qualityLevel;
    }
    
    // ğŸ”§ ì¶”ê°€: ì‘ë‹µì— ì‚¬ìš©ëœ API í‚¤ ì •ë³´ í¬í•¨
    result.usedUserKey = isUserKey;
    
    return {
      statusCode: 200,
      headers: { ...commonHeaders, 'Content-Type': 'application/json' },
      body: JSON.stringify(result),
    };
    
  } catch (error) {
    console.error('[Translation] ë²ˆì—­ ì²˜ë¦¬ ì˜¤ë¥˜:', error);
    return {
      statusCode: 500,
      headers: { ...commonHeaders, 'Content-Type': 'application/json' },
      body: JSON.stringify({ error: `ë²ˆì—­ ì‹¤íŒ¨: ${error.message}` })
    };
  }
      
      return {
        statusCode: 200,
        headers: { ...commonHeaders, 'Content-Type': 'application/json' },
        body: JSON.stringify(result),
      };

    } else if (action === 'speak') {
  if (!inputText) {
    return { 
      statusCode: 400, 
      headers: { ...commonHeaders, 'Content-Type': 'application/json' }, 
      body: JSON.stringify({ error: "inputTextê°€ í•„ìš”í•©ë‹ˆë‹¤." }) 
    };
  }
  
  // ğŸ”§ ê°œì„ : TTS API í‚¤ ì„ íƒ ë¡œì§
  const ttsApiKey = userApiKeys?.openai || OPENAI_API_KEY;
  const isUserKey = !!userApiKeys?.openai;
  
  let audioBuffer;
  
  console.log('[Speak] ìš”ì²­ ë°›ìŒ:', { 
    language, 
    voice,
    voiceName,
    useGoogleTTS,
    textLength: inputText.length,
    usingUserKey: isUserKey
  });
  
  try {
    // TTS ì—”ì§„ ì„ íƒ ë¡œì§
    if (useGoogleTTS === true) {
      console.log('[Speak] Google TTS ì„ íƒ (ëª…ì‹œì )');
      
      let languageCode = 'vi-VN';
      if (language === 'Korean') {
        languageCode = 'ko-KR';
      } else if (language === 'English') {
        languageCode = 'en-US';
      } else if (language === 'Vietnamese') {
        languageCode = 'vi-VN';
      }
      
      try {
        audioBuffer = await getGoogleTTS(
          inputText, 
          languageCode,
          voiceName || null,
          1.0
        );
        console.log('[Speak] Google TTS ì„±ê³µ');
      } catch (e) {
        console.error('[Speak] Google TTS ì‹¤íŒ¨, OpenAIë¡œ ì „í™˜:', e.message);
        audioBuffer = await getOpenAITTS(inputText, voice || 'nova', ttsApiKey);
      }
      
    } else if (useGoogleTTS === false) {
      console.log('[Speak] OpenAI TTS ì„ íƒ (ëª…ì‹œì )');
      
      try {
        audioBuffer = await getOpenAITTS(inputText, voice || 'nova', ttsApiKey);
        console.log('[Speak] OpenAI TTS ì„±ê³µ');
        
        // ğŸ”§ ì¶”ê°€: ì‚¬ìš©ëŸ‰ ì¶”ì  (OpenAI TTS ì‚¬ìš© ì‹œ)
        if (userId) {
          const cost = inputText.length * 0.000015;
          await trackUsage(userId, 'tts', inputText.length, cost, 'openai');
          console.log(`[Usage] TTS ì‚¬ìš©ëŸ‰ ì¶”ì : ${inputText.length}ì, ë¹„ìš©: $${cost.toFixed(6)}`);
        }
      } catch (e) {
        console.error('[Speak] OpenAI TTS ì‹¤íŒ¨:', e.message);
        
        let languageCode = 'vi-VN';
        if (language === 'Korean') languageCode = 'ko-KR';
        else if (language === 'English') languageCode = 'en-US';
        
        try {
          audioBuffer = await getGoogleTTS(inputText, languageCode, voiceName, 1.0);
          console.log('[Speak] Google TTS í´ë°± ì„±ê³µ');
        } catch (fallbackErr) {
          throw new Error('ëª¨ë“  TTS ì—”ì§„ ì‹¤íŒ¨');
        }
      }
      
    } else {
      console.log('[Speak] TTS ìë™ ì„ íƒ ëª¨ë“œ');
      
      if (inputText.length < 50) {
        let languageCode = 'vi-VN';
        if (language === 'Korean') languageCode = 'ko-KR';
        else if (language === 'English') languageCode = 'en-US';
        
        audioBuffer = await getGoogleTTS(inputText, languageCode, voiceName, 1.0);
      } else {
        audioBuffer = await getOpenAITTS(inputText, voice || 'nova', ttsApiKey);
        
        // ğŸ”§ ì¶”ê°€: ìë™ ëª¨ë“œì—ì„œ OpenAI ì‚¬ìš© ì‹œ ì‚¬ìš©ëŸ‰ ì¶”ì 
        if (userId) {
          const cost = inputText.length * 0.000015;
          await trackUsage(userId, 'tts', inputText.length, cost, 'openai');
          console.log(`[Usage] ìë™ëª¨ë“œ TTS ì‚¬ìš©ëŸ‰ ì¶”ì : ${inputText.length}ì, ë¹„ìš©: $${cost.toFixed(6)}`);
        }
      }
    }
    
    if (!audioBuffer || audioBuffer.length === 0) {
      console.error('[Speak] ì˜¤ë””ì˜¤ ë²„í¼ê°€ ë¹„ì–´ìˆìŒ');
      return {
        statusCode: 500,
        headers: { ...commonHeaders, 'Content-Type': 'application/json' },
        body: JSON.stringify({ error: 'ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨ - ë¹ˆ ë²„í¼' })
      };
    }
    
    console.log('[Speak] ìµœì¢… ë²„í¼ í¬ê¸°:', audioBuffer.length);
    
    return {
      statusCode: 200,
      headers: { ...commonHeaders, 'Content-Type': 'audio/mpeg' },
      isBase64Encoded: true,
      body: audioBuffer.toString('base64'),
    };
    
  } catch (error) {
    console.error('[Speak] TTS ì²˜ë¦¬ ì˜¤ë¥˜:', error);
    return {
      statusCode: 500,
      headers: { ...commonHeaders, 'Content-Type': 'application/json' },
      body: JSON.stringify({ error: `TTS ì‹¤íŒ¨: ${error.message}` })
    };
  }
      
    } else if (action === 'speak-chunk') {
      if (!inputText) {
        return { 
          statusCode: 400, 
          headers: { ...commonHeaders, 'Content-Type': 'application/json' }, 
          body: JSON.stringify({ error: "inputTextê°€ í•„ìš”í•©ë‹ˆë‹¤." }) 
        };
      }
      
      const chunks = splitIntoSentences(inputText);
      const idx = parseInt(chunkIndex || 0);
      
      if (idx >= chunks.length) {
        return { 
          statusCode: 200, 
          headers: { ...commonHeaders, 'Content-Type': 'application/json' }, 
          body: JSON.stringify({ completed: true, totalChunks: chunks.length }) 
        };
      }
      
      const chunkText = chunks[idx];
      let audioBuffer;
      
      if (useGoogleTTS === true) {
        let languageCode = 'vi-VN';
        if (language === 'Korean') languageCode = 'ko-KR';
        else if (language === 'English') languageCode = 'en-US';
        
        try {
          audioBuffer = await getGoogleTTS(
            chunkText, 
            languageCode,
            voiceName || null,
            1.0
          );
        } catch (e) {
          return {
            statusCode: 500,
            headers: { ...commonHeaders, 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
              error: 'ì²­í¬ ìŒì„± ìƒì„± ì‹¤íŒ¨',
              details: e.message 
            })
          };
        }
      } else {
        audioBuffer = await getOpenAITTS(chunkText, voice || 'alloy');
      }
      
      return {
        statusCode: 200,
        headers: { ...commonHeaders, 'Content-Type': 'application/json' },
        body: JSON.stringify({
          audio: audioBuffer.toString('base64'),
          chunkIndex: idx,
          totalChunks: chunks.length,
          text: chunkText,
          completed: false
        }),
      };
      
    } else {
      return { 
        statusCode: 400, 
        headers: { ...commonHeaders, 'Content-Type': 'application/json' }, 
        body: JSON.stringify({ error: `ì•Œ ìˆ˜ ì—†ëŠ” action: '${action}'` }) 
      };
    }
  } catch (err) {
    console.error("í•¸ë“¤ëŸ¬ ì˜¤ë¥˜ ë°œìƒ:", err);
    return {
      statusCode: 500,
      headers: { ...commonHeaders, 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        error: err.message || 'ì„œë²„ ì˜¤ë¥˜',
        stack: process.env.NODE_ENV === 'development' ? err.stack : undefined
      }),
    };
  }
};